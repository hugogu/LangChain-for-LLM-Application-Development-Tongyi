{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22643b33",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "- ConversationBufferMemory\n",
    "- ConversationBufferWindowMemory\n",
    "- ConversationTokenBufferMemory\n",
    "- ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8948c",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "id": "64224484",
   "metadata": {},
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0be64d03",
   "metadata": {},
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcf8cdb0",
   "metadata": {},
   "source": [
    "llm = ChatOpenAI(temperature=0.0,\n",
    "                 model=\"qwen-plus\",\n",
    "                 base_url=os.environ.get(\"OPENAI_API_URL\"))\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True,\n",
    "    memory = memory\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91b903be",
   "metadata": {},
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9963721e",
   "metadata": {},
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e77d0adb",
   "metadata": {},
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c2bf9f0",
   "metadata": {},
   "source": [
    "memory.load_memory_variables({})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b19fb0e4",
   "metadata": {},
   "source": [
    "memory = ConversationBufferMemory()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4c6056fe",
   "metadata": {},
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "513e13a9",
   "metadata": {},
   "source": [
    "print(memory.buffer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e97fab09",
   "metadata": {},
   "source": [
    "memory.load_memory_variables({})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9d4b10ab",
   "metadata": {},
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a539e0cc",
   "metadata": {},
   "source": [
    "memory.load_memory_variables({})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "638c5862",
   "metadata": {},
   "source": [
    "## Memory\n",
    "Large Language Models are 'stateless'\n",
    "- Each transaction is independent \n",
    "\n",
    "Chatbots appear to have memory ny providing the full conversation as 'context'\n",
    "\n",
    "LangChain provides several kinds of 'memory' to store and accumulate the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d366cf",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "id": "7f210ffa",
   "metadata": {},
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "acc95800",
   "metadata": {},
   "source": [
    "memory = ConversationBufferWindowMemory(k=1) "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "53f867a9",
   "metadata": {},
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a9605b29",
   "metadata": {},
   "source": [
    "memory.load_memory_variables({})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b3130e3",
   "metadata": {},
   "source": [
    "memory = ConversationBufferWindowMemory(k=1) # just remember 1 conversational exchange\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9756e140",
   "metadata": {},
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6110490d",
   "metadata": {},
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "53292aa0",
   "metadata": {},
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3f7acfed",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "id": "d365a523",
   "metadata": {},
   "source": "#!pip install tiktoken",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4dad29d2",
   "metadata": {},
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65ad1561",
   "metadata": {},
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a4ef354",
   "metadata": {},
   "source": [
    "memory.load_memory_variables({})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "63f7c539",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "id": "8faf8b89",
   "metadata": {},
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0,\n",
    "                 model=\"qwen-plus\",\n",
    "                 base_url=os.environ.get(\"OPENAI_API_URL\"),\n",
    "                 tiktoken_model_name=\"gpt-3.5-turbo\") # this tiktoken_model_name is to by-pass get_num_tokens_from_messages on ChatOpenAI which only support gpt series models."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86f7ff84",
   "metadata": {},
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68a6bf1a",
   "metadata": {},
   "source": [
    "memory.load_memory_variables({})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d085b3a1",
   "metadata": {},
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "17384ba8",
   "metadata": {},
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4eabfb36",
   "metadata": {},
   "source": [
    "memory.load_memory_variables({})"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
